{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TRAIN_CSV_FILE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[39mprint\u001b[39m(data\u001b[39m.\u001b[39mhead())\n\u001b[1;32m     36\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n\u001b[0;32m---> 38\u001b[0m trainData \u001b[39m=\u001b[39m preProcessData(TRAIN_CSV_FILE)\n\u001b[1;32m     39\u001b[0m testData \u001b[39m=\u001b[39m preProcessData(TEST_CSV_FILE)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TRAIN_CSV_FILE' is not defined"
     ]
    }
   ],
   "source": [
    "#Reading a dataset and convert file name to corresbonding umnber\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def preProcessData(csvFileName):\n",
    "    print(csvFileName+ \" will be preprocessed\")\n",
    "    data = pd.read_csv(csvFileName,skipinitialspace=True)\n",
    "    # we have six speakers: \n",
    "    # 0: Jackson\n",
    "    # 1: Nicolas \n",
    "    \n",
    "    filenameArray = data['filename'] \n",
    "    speakerArray = []\n",
    "    #print(filenameArray)\n",
    "    for i in range(len(filenameArray)):\n",
    "        speaker = filenameArray[i][1]\n",
    "        #print(speaker)\n",
    "        if speaker == \"e\":\n",
    "            speaker = 0\n",
    "        elif speaker == \"o\":\n",
    "            speaker = 1\n",
    "        #print(speaker)\n",
    "        speakerArray.append(speaker)\n",
    "    data['number'] = speakerArray\n",
    "    data['number'] = data.number.astype(float)\n",
    "    #Dropping unnecessary columns\n",
    "    data = data.drop(['filename'],axis=1)\n",
    "    data = data.drop(['label'],axis=1)\n",
    "    data = data.drop(['chroma_stft'],axis=1)\n",
    "    data.shape\n",
    "\n",
    "    print(\"Preprocessing is finished\")\n",
    "    print(data.head())\n",
    "    return data\n",
    "\n",
    "trainData = preProcessData(TRAIN_CSV_FILE)\n",
    "testData = preProcessData(TEST_CSV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(trainData)\n",
    "a.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#secation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training, validation and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = np.array(trainData.iloc[:, :-1], dtype = float)\n",
    "y = trainData.iloc[:, -1]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "X_test = np.array(testData.iloc[:, :-1], dtype = float)\n",
    "y_test = testData.iloc[:, -1]\n",
    "\n",
    "print(\"Y from training data:\", y_train.shape)\n",
    "print(\"Y from validation data:\", y_val.shape)\n",
    "print(\"Y from test data:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform( X_train )\n",
    "X_val = scaler.transform( X_val )\n",
    "X_test = scaler.transform( X_test )\n",
    "\n",
    "print(\"X from training data\", X_train.shape)\n",
    "print(\"X from validation data\", X_val.shape)\n",
    "print(\"X from test data\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import keras\n",
    "\n",
    "# model 1\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Learning Process of a model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# simple early stopping\n",
    "# from keras.callbacks import EarlyStopping\n",
    "\n",
    "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "#Train with early stopping to avoid overfitting\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=50,\n",
    "                    batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training history\n",
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpeaker(speaker):\n",
    "    speaker = int(speaker)\n",
    "    if speaker == 0:\n",
    "        return \"rehan\"\n",
    "    elif speaker == 1:\n",
    "        return \"rohit\"\n",
    "    else: \n",
    "        speaker = \"Unknown\"\n",
    "        \n",
    "def printPrediction(X_data, y_data, printDigit):\n",
    "    print('\\n# Generate predictions')\n",
    "    for i in range(len(y_data)):\n",
    "        prediction = getSpeaker(model.predict(X_data[i:i+1])[0])\n",
    "        speaker = getSpeaker(y_data[i])\n",
    "        if printDigit == True:\n",
    "            print(\"Number={0:d}, y={1:1s}- prediction={2:1s}- match={3}\".format(i, speaker, prediction, speaker==prediction))\n",
    "        else:\n",
    "            print(\"y={0:1s}- prediction={1:1s}- match={2}\".format(speaker, prediction, speaker==prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def report(X_data, y_data):\n",
    "    #Confution Matrix and Classification Report\n",
    "    Y_pred = model.predict_classes(X_data)\n",
    "    y_test_num = y_data.astype(np.int64)\n",
    "    conf_mt = confusion_matrix(y_test_num, Y_pred)\n",
    "    print(conf_mt)\n",
    "    plt.matshow(conf_mt)\n",
    "    plt.show()\n",
    "    print('\\nClassification Report')\n",
    "    target_names = [\"rehan\", \"rohit\", \"Unknown\"]\n",
    "    print(classification_report(y_test_num, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.25404652, -0.20046474, -0.47254028, -0.28582484, -0.21384803,\n",
       "       -0.56463361, -0.36600709,  0.53634153, -0.87493699, -0.4132182 ,\n",
       "        0.7661111 , -1.65515082, -0.02226974, -0.14299251, -1.56797383,\n",
       "       -1.40874715, -1.74326182,  1.07789344,  0.18673799, -0.61989354,\n",
       "        1.03725701,  0.56238464, -0.6220815 ,  0.27881582, -1.56647066])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATE_CSV_FILES = True\n",
    "# print(str(int(y_test[1])))\n",
    "X_test[0:0+1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# TEST DATA #\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0889e-04 - accuracy: 1.0000\n",
      "accuracy: 100.00%\n",
      "\n",
      "# Generate predictions\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m%.2f\u001b[39;00m\u001b[39m%%\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (model\u001b[39m.\u001b[39mmetrics_names[\u001b[39m1\u001b[39m], score[\u001b[39m1\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m))\n\u001b[1;32m      5\u001b[0m \u001b[39m# Prediction\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m printPrediction(X_test[\u001b[39m0\u001b[39;49m:\u001b[39m10\u001b[39;49m], y_test[\u001b[39m0\u001b[39;49m:\u001b[39m10\u001b[39;49m], \u001b[39mFalse\u001b[39;49;00m)\n",
      "Cell \u001b[0;32mIn[73], line 13\u001b[0m, in \u001b[0;36mprintPrediction\u001b[0;34m(X_data, y_data, printDigit)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m# Generate predictions\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(y_data)):\n\u001b[0;32m---> 13\u001b[0m     prediction \u001b[39m=\u001b[39m getSpeaker(model\u001b[39m.\u001b[39;49mpredict(X_data[i:i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m])[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m     14\u001b[0m     speaker \u001b[39m=\u001b[39m getSpeaker(y_data[i])\n\u001b[1;32m     15\u001b[0m     \u001b[39mif\u001b[39;00m printDigit \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[73], line 2\u001b[0m, in \u001b[0;36mgetSpeaker\u001b[0;34m(speaker)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetSpeaker\u001b[39m(speaker):\n\u001b[0;32m----> 2\u001b[0m     speaker \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(speaker)\n\u001b[1;32m      3\u001b[0m     \u001b[39mif\u001b[39;00m speaker \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m      4\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mrehan\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "print('\\n# TEST DATA #\\n')\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "# Prediction\n",
    "printPrediction(X_test[0:10], y_test[0:10], False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Test Data\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mClassification Report for Test Data\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m report(X_test, y_test)\n",
      "Cell \u001b[0;32mIn[39], line 11\u001b[0m, in \u001b[0;36mreport\u001b[0;34m(X_data, y_data)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreport\u001b[39m(X_data, y_data):\n\u001b[1;32m     10\u001b[0m     \u001b[39m#Confution Matrix and Classification Report\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     Y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict_classes(X_data)\n\u001b[1;32m     12\u001b[0m     y_test_num \u001b[39m=\u001b[39m y_data\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mint64)\n\u001b[1;32m     13\u001b[0m     conf_mt \u001b[39m=\u001b[39m confusion_matrix(y_test_num, Y_pred)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Test Data\\n\")\n",
    "report(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV_FILE = \"train.csv\"\n",
    "TEST_CSV_FILE = \"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CREATE_CSV_FILES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m     file\u001b[39m.\u001b[39mclose()\n\u001b[1;32m     38\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEnd of extractWavFeatures\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m \u001b[39mif\u001b[39;00m (CREATE_CSV_FILES \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m     41\u001b[0m     extractWavFeatures(\u001b[39m\"\u001b[39m\u001b[39m./train\u001b[39m\u001b[39m\"\u001b[39m, TRAIN_CSV_FILE)\n\u001b[1;32m     42\u001b[0m     extractWavFeatures(\u001b[39m\"\u001b[39m\u001b[39m./test\u001b[39m\u001b[39m\"\u001b[39m, TEST_CSV_FILE)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CREATE_CSV_FILES' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import librosa\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def extractWavFeatures(soundFilesFolder, csvFileName):\n",
    "    print(\"The features of the files in the folder \"+soundFilesFolder+\" will be saved to \"+csvFileName)\n",
    "    header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "    for i in range(1, 21):\n",
    "        header += f' mfcc{i}'\n",
    "    header += ' label'\n",
    "    header = header.split()\n",
    "    print('CSV Header: ', header)\n",
    "    file = open(csvFileName, 'w', newline='')\n",
    "    #with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    genres = '1 2 3 4 5 6 7 8 9 0'.split()\n",
    "    for filename in os.listdir(soundFilesFolder):\n",
    "        number = f'{soundFilesFolder}/{filename}'\n",
    "        y, sr = librosa.load(number, mono=True, duration=30)\n",
    "        # remove leading and trailing silence\n",
    "        y, index = librosa.effects.trim(y)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        rmse = librosa.feature.rms(y=y)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        writer.writerow(to_append.split())\n",
    "    file.close()\n",
    "    print(\"End of extractWavFeatures\")\n",
    "\n",
    "if (CREATE_CSV_FILES == True):\n",
    "    extractWavFeatures(\"./train\", TRAIN_CSV_FILE)\n",
    "    extractWavFeatures(\"./test\", TEST_CSV_FILE)\n",
    "    print(\"CSV files are created\")\n",
    "else:\n",
    "    print(\"CSV files creation is skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
